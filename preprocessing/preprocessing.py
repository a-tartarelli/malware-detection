import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_validate
from sklearn.metrics import recall_score
from sklearn.preprocessing import LabelEncoder
from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder

#lettura dataset
features = pd.read_csv('dataset/apimds.csv', sep=";")
goodware = pd.read_csv('dataset/goodware.csv')

#drop colonna nome del software e del relativo hash code
features= features.drop("Column1", axis = 1)
features= features.drop("Column2", axis = 1)

#aggiunta labels per identificare i malware e i goodware
features["malware"] = 1
goodware["malware"] = 0

#unione dei tuo dataset in un unico dataframe
df3 = features.append(goodware, ignore_index=True)

#eliminazione valori mancanti
df3 = df3.dropna(axis=0)

#mescolamento dataframe per evitare che tutti i goodware si trovino in coda
df3 = df3.sample(frac=1).reset_index(drop=True)

#copia delle labels ed eliminazione dal dataframe
malwareCol = df3['malware'].copy()
df3 = df3.drop('malware', axis = 1)

#estrapolazione delle categotys, ovvero di tutte le chiamate API presenti nel dataset
s = set()
for i in range(0, 21789):
    labels = np.array(df3.iloc[i])
    #print(labels)
    #value = str(features.iloc[i])
    for l in labels:
        ss = str(l).strip()
        s.add(ss)

#categorycal encoding
calls = list(s)
le = LabelEncoder()
le.fit(calls)

for i in range(3, 110):
    df3["Column" + str(i)] = le.transform(df3["Column" + str(i)])

#oneHotencoding
onehot = OneHotEncoder()
newframe_1hot = onehot.fit_transform(df3)

#conversione in numpyarray con relativa espanzione della SciPy sparse matrix
newframe_1hot = newframe_1hot.toarray()

from sklearn.preprocessing import StandardScaler

# create a scaler object
std_scaler = StandardScaler()

# fit and transform the data
df_std = pd.DataFrame(std_scaler.fit_transform(newframe_1hot))

# Split the data into training and testing sets
train_features, test_features, train_labels, test_labels = train_test_split(df_std, malwareCol, test_size = 0.2, random_state=42)

#Instantiate model with 100 decision trees
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(verbose=1, n_jobs=-1, criterion="gini", n_estimators=100)
scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'roc_auc']
scores = cross_validate(rf, train_features, train_labels, cv=10, scoring=scoring)

#risultati
print("%0.5f precision" % (scores['test_precision_macro'].mean()))
print("%0.5f recall" % (scores['test_recall_macro'].mean()))
print("%0.5f f1 score" % (scores['test_f1_macro'].mean()))
print("%0.3f auc roc" % (scores['test_roc_auc'].mean()))

print("%0.3f training time" % (scores['fit_time'].sum()))
print("%0.3f predition time" % (scores['score_time'].sum()))