{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000 precision\n",
      "0.9983 recall\n",
      "0.9991 f1 score\n",
      "1.0000 auc roc\n",
      "2.05634 training time\n",
      "2.00587 predition time\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Carica il dataset\n",
    "df = pd.read_csv('../dataset/apimdsFinal.csv')\n",
    "\n",
    "# Definisci la colonna da escludere dal OneHotEncoding\n",
    "col_to_exclude = 'malware'\n",
    "\n",
    "# Estrai i nomi delle colonne che devono essere sottoposte a OneHotEncoding\n",
    "columns_to_encode = [col for col in df.columns if col != col_to_exclude]\n",
    "\n",
    "# Inizializza il ColumnTransformer con l'OneHotEncoder per le colonne selezionate\n",
    "ct = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), columns_to_encode)],\n",
    "                       remainder='passthrough')\n",
    "\n",
    "# Applica il ColumnTransformer al dataset\n",
    "X_encoded = ct.fit_transform(df)\n",
    "\n",
    "# Esegui l'undersampling\n",
    "#rus = RandomUnderSampler(sampling_strategy=0.1)\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_encoded, df['malware'])\n",
    "y_resampled = df['malware']\n",
    "\n",
    "# Inizializza il modello di Random Forest\n",
    "#rf_model = RandomForestClassifier(criterion='gini', n_estimators=100, max_features=114)\n",
    "\n",
    "# Definisci il numero di fold per il K-Fold\n",
    "#n_splits = 10\n",
    "\n",
    "# Inizializza il K-Fold\n",
    "#kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=46)\n",
    "\n",
    "# Inizializza le liste per le metriche di valutazione\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "steps = [('under', RandomUnderSampler(sampling_strategy=0.5)), ('model', RandomForestClassifier(criterion='gini', n_estimators=100, max_features=114))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'roc_auc']\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=23)\n",
    "scores = cross_validate(pipeline, X_encoded, y_resampled, scoring=scoring, cv=cv)\n",
    "\n",
    "\"\"\"\n",
    "# Esegui il K-Fold\n",
    "for train_index, test_index in kf.split(X_resampled):\n",
    "    X_train, X_test = X_resampled[train_index], X_resampled[test_index]\n",
    "    y_train, y_test = y_resampled[train_index], y_resampled[test_index]\n",
    "    \n",
    "    # Addestra il modello\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Effettua le predizioni\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Calcola le metriche di valutazione\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_test, y_pred, average='macro', multi_class='ovr')\n",
    "    \n",
    "    # Aggiungi le metriche alla lista corrispondente\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "# Calcola la media delle metriche di valutazione\n",
    "avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "avg_roc_auc = sum(roc_auc_scores) / len(roc_auc_scores)\n",
    "\n",
    "\n",
    "# Stampa le metriche di valutazione\n",
    "print(\"Precision macro:\", avg_precision)\n",
    "print(\"Recall macro:\", avg_recall)\n",
    "print(\"F1 score macro:\", avg_f1)\n",
    "print(\"ROC AUC:\", avg_roc_auc)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"%0.4f precision\" % (scores['test_precision_macro'].mean()))\n",
    "print(\"%0.4f recall\" % (scores['test_recall_macro'].mean()))\n",
    "print(\"%0.4f f1 score\" % (scores['test_f1_macro'].mean()))\n",
    "print(\"%0.4f auc roc\" % (scores['test_roc_auc'].mean()))\n",
    "\n",
    "print(\"%0.5f training time\" % (scores['fit_time'].sum()))\n",
    "print(\"%0.5f predition time\" % (scores['score_time'].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Lasso(alpha=0.01)' (type <class 'sklearn.linear_model._coordinate_descent.Lasso'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alessio/code/python/malware-detection/apimds/test.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m X_resampled \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([num_X_resampled, OH_cols], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# definizione del pipeline\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model \u001b[39m=\u001b[39m make_pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     Lasso(alpha\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     RandomForestClassifier(n_estimators\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# k-fold cross validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alessio/code/python/malware-detection/apimds/test.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m cv \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:872\u001b[0m, in \u001b[0;36mmake_pipeline\u001b[0;34m(memory, verbose, *steps)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_pipeline\u001b[39m(\u001b[39m*\u001b[39msteps, memory\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    828\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct a :class:`Pipeline` from the given estimators.\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \n\u001b[1;32m    830\u001b[0m \u001b[39m    This is a shorthand for the :class:`Pipeline` constructor; it does not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39m                    ('gaussiannb', GaussianNB())])\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     \u001b[39mreturn\u001b[39;00m Pipeline(_name_estimators(steps), memory\u001b[39m=\u001b[39;49mmemory, verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:148\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39m=\u001b[39m memory\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m verbose\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:207\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    205\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[0;32m--> 207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    214\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    216\u001b[0m     estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m ):\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'Lasso(alpha=0.01)' (type <class 'sklearn.linear_model._coordinate_descent.Lasso'>) doesn't"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# caricamento dati\n",
    "df = pd.read_csv('../dataset/apimdsFinal.csv')\n",
    "\n",
    "# Definisci la colonna da escludere dal OneHotEncoding\n",
    "col_to_exclude = 'malware'\n",
    "\n",
    "# selezione delle feature desiderate\n",
    "selected_features = [col for col in df.columns if col != col_to_exclude]\n",
    "X = df[selected_features]\n",
    "y = df['malware']\n",
    "\n",
    "# undersampling\n",
    "rus = RandomUnderSampler()\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Estrai i nomi delle colonne che devono essere sottoposte a OneHotEncoding\n",
    "#columns_to_encode = [col for col in df.columns if col != col_to_exclude]\n",
    "\n",
    "# one-hot encoding\n",
    "categorical_cols = [col for col in df.columns if col != col_to_exclude]\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(X_resampled[categorical_cols]))\n",
    "OH_cols.index = X_resampled.index\n",
    "num_X_resampled = X_resampled.drop(categorical_cols, axis=1)\n",
    "X_resampled = pd.concat([num_X_resampled, OH_cols], axis=1)\n",
    "\n",
    "# definizione del pipeline\n",
    "model = make_pipeline(\n",
    "    Lasso(alpha=0.01),\n",
    "    RandomForestClassifier(n_estimators=100)\n",
    ")\n",
    "\n",
    "# k-fold cross validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "for train_index, test_index in cv.split(X_resampled, y_resampled):\n",
    "    # undersampling\n",
    "    X_train, y_train = X_resampled.iloc[train_index], y_resampled[train_index]\n",
    "    X_test, y_test = X_resampled.iloc[test_index], y_resampled[test_index]\n",
    "    rus = RandomUnderSampler()\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    # one-hot encoding\n",
    "    OH_cols = pd.DataFrame(OH_encoder.transform(X_train_resampled[categorical_cols]))\n",
    "    OH_cols.index = X_train_resampled.index\n",
    "    num_X_train_resampled = X_train_resampled.drop(categorical_cols, axis=1)\n",
    "    X_train_resampled = pd.concat([num_X_train_resampled, OH_cols], axis=1)\n",
    "\n",
    "    # addestramento del modello\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # valutazione del modello\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    roc_auc_scores.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(\"Precision macro:\", np.mean(precision_scores))\n",
    "print(\"Recall macro:\", np.mean(recall_scores))\n",
    "print(\"F1 score macro:\", np.mean(f1_scores))\n",
    "print(\"ROC AUC:\", np.mean(roc_auc_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
