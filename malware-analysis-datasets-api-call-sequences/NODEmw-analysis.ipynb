{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2Ms420a8Pz7",
    "outputId": "929b3040-2c93-4790-d3da-966bbb5f9706"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888 precision\n",
      "0.7624 recall\n",
      "0.8376 f1-score\n",
      "0.7624 rocauc\n",
      "454.82560 training_time\n",
      "28.85208 pred_time\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "relusts = pd.read_csv('resultsNODEmw-analysisColab.csv')\n",
    "\n",
    "print(\"%0.4f precision\" % relusts['precision'].mean())\n",
    "print(\"%0.4f recall\" %relusts['recall'].mean())\n",
    "print(\"%0.4f f1-score\" %relusts['f1-score'].mean())\n",
    "print(\"%0.4f rocauc\" %relusts['rocauc'].mean())\n",
    "print(\"%0.5f training_time\" %relusts['training_time'].mean())\n",
    "print(\"%0.5f pred_time\" %relusts['pred_time'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m3WtA2wA6FZN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, os\n",
    "\n",
    "localPath = '../dataset/folds/mw-analysis'\n",
    "#localPath = '/content/drive/MyDrive/datasetTesi/apimds'\n",
    "\n",
    "getColumnsName = pd.read_csv(localPath + '/X_train_fold_' + str(1) + '.csv', dtype='category')\n",
    "\n",
    "head = getColumnsName.columns.values.tolist()\n",
    "\n",
    "def readFold(foldNum):\n",
    "    X_train = pd.read_csv(localPath + '/X_train_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "    Y_train = pd.read_csv(localPath + '/y_train_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "\n",
    "    X_test = pd.read_csv(localPath + '/X_test_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "    Y_test = pd.read_csv(localPath + '/y_test_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def readFoldPredict(foldNum):\n",
    "    X_eval = pd.read_csv(localPath + '/X_test_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "    Y_eval = pd.read_csv(localPath + '/y_test_fold_' + str(foldNum) + '.csv', dtype='category')\n",
    "\n",
    "    return X_eval, Y_eval\n",
    "\n",
    "\n",
    "def writeMetrics(metrics):\n",
    "    fields = [\"precision\", \"recall\", 'f1-score', 'rocauc', 'training_time', 'pred_time']\n",
    "\n",
    "    with open('resultsNODEmw-analysis.csv', 'a+') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if os.stat(\"resultsNODEapimds.csv\").st_size == 0:\n",
    "            writer.writerow(fields)\n",
    "        \n",
    "        writer.writerow(metrics)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def toCatAndConcat(X_train, X_test):\n",
    "  #X_train[head] = X_train[head].apply(lambda x: x.cat.codes)\n",
    "  #X_test[head] = X_test[head].apply(lambda x: x.cat.codes)\n",
    "\n",
    "  trainFull = pd.concat([X_train, Y_train], axis=1)\n",
    "  testFull = pd.concat([X_test, Y_test], axis=1)\n",
    "\n",
    "  return trainFull, testFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25f9JchC6FZS"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EaA7zix6FZS"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_tabnet --break-system-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhYKtBJz6FZT",
    "outputId": "e94917f5-2a0a-4714-f8a1-7ce8aa6e3b45"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using {}\".format(DEVICE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFull.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_tabular/models/node/config.py:232: UserWarning: embed_categorical is set to False and will use LeaveOneOutEncoder to encode categorical features. This is deprecated and will be removed in future versions and categorical columns will be embedded by default.\n",
      "  \"embed_categorical is set to False and will use LeaveOneOutEncoder to encode categorical features.\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malex1643-a\u001b[0m (\u001b[33mmadminds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850b9e48a8be4f99ab0b5c9f567b6a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113027399999788, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230912_121327-23j1ulj6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/madminds/PyTorch%20Tabular%20Example/runs/23j1ulj6' target=\"_blank\">synthetic_classification_node_4</a></strong> to <a href='https://wandb.ai/madminds/PyTorch%20Tabular%20Example' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/madminds/PyTorch%20Tabular%20Example' target=\"_blank\">https://wandb.ai/madminds/PyTorch%20Tabular%20Example</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/madminds/PyTorch%20Tabular%20Example/runs/23j1ulj6' target=\"_blank\">https://wandb.ai/madminds/PyTorch%20Tabular%20Example/runs/23j1ulj6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NODE model config\n",
    "from pytorch_tabular import TabularModel \n",
    "from pytorch_tabular.models import NodeConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['malware'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    categorical_cols=head,\n",
    "    num_workers=8\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=512,\n",
    "    accumulate_grad_batches=16,\n",
    "    max_epochs=100,\n",
    "    early_stopping=\"valid_loss\", # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode = \"min\", # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5, # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\", # Save best checkpoint monitoring val_loss\n",
    "    load_best=True, # After training, load the best checkpoint\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "# NODE has a custom head and any head we define will be ignored\n",
    "model_config = NodeConfig(\n",
    "    task=\"classification\",\n",
    "    num_trees=512,\n",
    "    depth=4,\n",
    "    num_layers=2,\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "experiment_config = ExperimentConfig(project_name=\"PyTorch Tabular Example\", \n",
    "                                     run_name=\"synthetic_classification_node\", \n",
    "                                     exp_watch=\"gradients\", \n",
    "                                     log_target=\"wandb\", \n",
    "                                     log_logits=True)\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    experiment_config=experiment_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "2023-09-12 12:13:57,113 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-09-12 12:13:57,120 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for classification task\n",
      "2023-09-12 12:13:59,707 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: NODEModel\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_tabular/models/node/node_model.py:117: UserWarning: Ignoring head config because NODE has a specific head which subsets the tree outputs\n",
      "  warnings.warn(\"Ignoring head config because NODE has a specific head which subsets the tree outputs\")\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_tabular/models/base_model.py:148: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  \"Plotly is not installed. Please install plotly to log logits. \"\n",
      "2023-09-12 12:13:59,814 - {pytorch_tabular.models.node.node_model:83} - INFO - Data Aware Initialization of NODE using a forward pass with 2000 batch size....\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "2023-09-12 12:14:04,960 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:590: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  \"The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0.\"\n",
      "Auto select gpus: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-09-12 12:14:05,014 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /home/alessio/code/python/malware-detection/malware-analysis-datasets-api-call-sequences/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ NODEBackbone      │  5.7 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ PreEncoded1dLayer │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Lambda            │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss  │      0 │\n",
       "└───┴──────────────────┴───────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ NODEBackbone      │  5.7 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ PreEncoded1dLayer │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Lambda            │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss  │      0 │\n",
       "└───┴──────────────────┴───────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 5.7 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 258                                                                                          \n",
       "<span style=\"font-weight: bold\">Total params</span>: 5.7 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 22                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 5.7 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 258                                                                                          \n",
       "\u001b[1mTotal params\u001b[0m: 5.7 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 22                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866fdfa669714cd3b858d31b910b9e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning:\n",
       "Detected KeyboardInterrupt, attempting graceful shutdown...\n",
       "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 12:14:54,169 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-09-12 12:14:54,171 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_lightning/utilities/cloud_io.py:34: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.cloud_io.get_filesystem` instead.\n",
      "  \"`pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0744e57171b4742ac7facdc6172c86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_tabular/tabular_model.py:1239: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  pred_df[f\"{class_}_probability\"] = point_predictions[:, i]\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/pytorch_tabular/tabular_model.py:1241: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  np.argmax(point_predictions, axis=1)\n",
      "/home/alessio/anaconda3/envs/tesiMsi/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0518797909999904\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resultsNODEapimds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4702/1581187961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimePred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mwriteMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4702/2443490125.py\u001b[0m in \u001b[0;36mwriteMetrics\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resultsNODEmw-analysis.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resultsNODEapimds.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resultsNODEapimds.csv'"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "for i in range(0, 10):\n",
    "    X_train, Y_train, X_test, Y_test = readFold(i)\n",
    "    trainFull, testFull = toCatAndConcat(X_train, X_test)\n",
    "\n",
    "    start = time.process_time()\n",
    "    tabular_model.fit(train=trainFull, validation=testFull)\n",
    "    trainTime = time.process_time() - start\n",
    "\n",
    "    numfoldEval = random.randint(0, 9)\n",
    "    if numfoldEval != i:\n",
    "        X_eval, Y_eval = readFoldPredict(numfoldEval)\n",
    "        #X_eval[head] = X_eval[head].apply(lambda x: x.cat.codes)\n",
    "\n",
    "        startPred = time.process_time()\n",
    "        result = tabular_model.predict(X_eval)\n",
    "        timePred = time.process_time() - startPred\n",
    "        print(timePred)\n",
    "\n",
    "    metrics = list()\n",
    "\n",
    "    metrics.append(precision_score(Y_eval, result[\"prediction\"], average='macro'))\n",
    "    metrics.append(recall_score(Y_eval, result[\"prediction\"], average='macro'))\n",
    "    metrics.append(f1_score(Y_eval, result[\"prediction\"], average='macro'))\n",
    "    metrics.append(roc_auc_score(Y_eval, result[\"prediction\"], average='macro'))\n",
    "    metrics.append(trainTime)\n",
    "    metrics.append(timePred)\n",
    "\n",
    "    writeMetrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bach size 512 con categorical sulla fold, senza non funziona!\n",
    "\n",
    "[0.9957345971563981,\n",
    " 0.859375,\n",
    " 0.9160399809614469,\n",
    " 0.859375,\n",
    " 380.7003086410001,\n",
    " 44.24949922500002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIS7zQJB6FZV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using {}\".format(DEVICE))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
